{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Python Packages for Data Analysis\n",
    "\n",
    "In this course, we will use various Python packages to perform data manipulation, data analysis, data visualization, and numerical optimization.\n",
    "Python packages (or libraries) are collections of modules that provide specific functions or features. We can install and import these packages directly in our Google Colab notebooks to use them in our code. Below are some popular packages we will use and their purpose:\n",
    "\n",
    "- **Data handling and analysis**: These packages enable working with diverse data types like arrays, data frames, or time series. They also facilitate tasks like cleaning, processing, aggregating, and manipulating data. Key packages include:\n",
    "  - *NumPy*: Supports for multidimensional arrays and matrices, along with mathematical functions and operations on them. NumPy is ideal for scientific computing needs like creating/manipulating arrays, linear algebra, and mathematical applications.\n",
    "  - *Pandas*: Offers high-performance data structures and analysis tools for tabular data. Its DataFrame can store/process data in rows and columns with multiple methods for indexing, filtering, grouping, and reshaping. Pandas allows reading, writing, and exploring data from sources like CSV, Excel, SQL, etc.\n",
    "- **Data visualization**: These packages help us to create and display graphical representations of data, such as charts, plots, or maps. They also enable customizing the appearance, style, and interactivity of the visualizations. The following key packages provide a variety of plots that are suitable for exploring and understanding data.\n",
    "  - *Matplotlib*: Leading Python plotting library to create and adapt figures, axes and other plot elements. It supports diverse plot types including bar, pie, scatter, histograms etc. We will employ Matplotlib for basic data visualization needs.\n",
    "  - *Seaborn*: High-level statistical data visualization build on Matplotlib. Seaborn Integrates well with Pandas offering enhanced, informative plots like heatmaps, boxplots etc. to represent data.\n",
    "- **Numerical optimization**: These packages help us to formulate and solve optimization problems, such as linear programming, integer programming, or nonlinear programming. They also provide tools for modeling, solving, and analyzing the results of the optimization problems. Some of the packages that we will use for this purpose are:\n",
    "  - *pyomo*: A Python-based open-source software for modeling and solving optimization problems. It supports a variety of problem types, such as linear, quadratic, nonlinear, mixed-integer, stochastic, and bilevel programming. It also supports a variety of solvers, such as GLPK, Gurobi, IBM Cplex, and more. We will model optimization problems in Pyomo leveraging its algebraic modeling capabilities.\n",
    "  - *glpk*: A free software for solving large-scale linear programming and mixed integer programming problems. It implements the simplex method, the interior-point method, and the branch-and-cut method. It also provides a standalone solver that can be called from the command line or from other programs. GLPK offers Python APIs to interface optimization problems.\n",
    "  - *gurobipy*: A Python interface for Gurobi, one of the leading commercial solvers that can handle various optimization problems, such as linear programming, mixed-integer programming, and quadratic programming. The GurobiPy package Provides Python binding to formulate and solve problems. We will use GurobiPy to integrate Gurobi with Pyomo.\n",
    "\n",
    "> *Note*: Commercial solvers like Gurobi usually have a free license installed by default for solving small-to-medium scale optimization problems. However, if you want to solve large-scale problems you need to obtain a Web License Service (WLS) license to work with Google Colab, which is free for academic purposes. For more info visit [this link](https://support.gurobi.com/hc/en-us/articles/4409582394769-Google-Colab-Installation-and-Licensing).\n",
    "\n",
    "To install python packages, we use the `!pip install` command in a code cell. This command will download and install the packages from the Python Package Index (PyPI), which is a repository of software for the Python programming language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Numpy: A package for scientific computing\n",
    "\n",
    "**NumPy** stands for Numerical Python and provides an efficient way to store and manipulate numerical data in Python. NumPy arrays are the main objects of the library, and they are similar to lists in Python, but can have any number of dimensions and store data of the same type. NumPy arrays are faster and more compact than lists, and support a wide range of mathematical operations and functions.\n",
    "\n",
    "To install NumPy, create a new code cell and run the following command to install the NumPy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will display the output of the installation process, such as the version of the package, the dependencies, and the location of the files.\n",
    "\n",
    "To use NumPy, you need to import it in your Python program. The convention is to use the alias `np` for NumPy, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NumPy arrays and matrices\n",
    "\n",
    "There are several ways to create NumPy arrays, depending on the source and shape of the data. Here are some common methods:\n",
    "\n",
    "- `np.array()`: This function takes a sequence (such as a list, tuple, or another array) and converts it into a NumPy array. You can specify the data type of the array using the `dtype` argument, otherwise it will be inferred from the data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-dimensional array from a list\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(a)\n",
    "# Output: [1 2 3 4 5]\n",
    "\n",
    "# Create a two-dimensional array (a matrix) from a nested list\n",
    "b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(b)\n",
    "# Output: [[1 2 3]\n",
    "#          [4 5 6]\n",
    "#          [7 8 9]]\n",
    "\n",
    "# Create an array of floating-point numbers from a range\n",
    "c = np.array(range(5), dtype=float)\n",
    "print(c)\n",
    "# Output: [0. 1. 2. 3. 4.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.arange()`: This function creates an array of evenly spaced values within a given interval. It takes three arguments: `start`, `stop`, and `step`, where `start` is the first value, `stop` is the last value (exclusive), and `step` is the increment. If only one argument is given, it is treated as `stop` and `start` is set to zero.\n",
    "- `np.linspace()`: This function creates an array of evenly spaced values within a given interval. It takes three arguments: `start`, `stop`, and `num`, where `start` is the first value, `stop` is the last value (inclusive), and `num` is the number of values. For example:\n",
    "  \n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of integers from 0 to 9\n",
    "d = np.arange(10)\n",
    "print(d)\n",
    "# Output: [0 1 2 3 4 5 6 7 8 9]\n",
    "\n",
    "# Create an array of odd numbers from 1 to 19\n",
    "e = np.arange(1, 20, 2)\n",
    "print(e)\n",
    "# Output: [ 1  3  5  7  9 11 13 15 17 19]\n",
    "\n",
    "# Create an array of 10 values from 0 to 1\n",
    "f = np.linspace(0, 1, 10)\n",
    "print(f)\n",
    "# Output: [0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n",
    "#          0.66666667 0.77777778 0.88888889 1.        ]\n",
    "\n",
    "# Create an array of 5 values from -1 to 1\n",
    "g = np.linspace(-1, 1, 5)\n",
    "print(g)\n",
    "# Output: [-1.  -0.5  0.   0.5  1. ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.zeros()`: This function creates an array of zeros with a given `shape`. The `shape` can be an integer or a tuple of integers, representing the size of each dimension. The data type of the array can be specified using the `dtype` argument, otherwise it will be `float`.\n",
    "- `np.ones()`: This function is similar to `np.zeros()`, except that it creates an array of ones with a given `shape`.\n",
    "- `np.full()`: This function is similar to `np.zeros()`, except that it creates an array of a specified value with a given `shape`.\n",
    "- `np.eye()`: This function creates an identity matrix with a given `n` dimension. The data type of the array can be specified using the `dtype` argument, otherwise it will be `float`.\n",
    "- `np.diag()`: This function creates a diagonal matrix with a given `values` array. The data type of the array can be specified using the `dtype` argument, otherwise it will be `float`.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-dimensional array of 5 zeros\n",
    "h = np.zeros(5)\n",
    "print(h)\n",
    "# Output: [0. 0. 0. 0. 0.]\n",
    "\n",
    "# Create a two-dimensional array of 3x4 zeros\n",
    "i = np.zeros((3, 4))\n",
    "print(i)\n",
    "# Output: [[0. 0. 0. 0.]\n",
    "#          [0. 0. 0. 0.]\n",
    "#          [0. 0. 0. 0.]]\n",
    "\n",
    "# Create a one-dimensional array of 5 ones\n",
    "j = np.ones(5)\n",
    "print(j)\n",
    "# Output: [1. 1. 1. 1. 1.]\n",
    "\n",
    "# Create a two-dimensional array of 3x4 ones\n",
    "k = np.ones((3, 4))\n",
    "print(k)\n",
    "# Output: [[1. 1. 1. 1.]\n",
    "#          [1. 1. 1. 1.]\n",
    "#          [1. 1. 1. 1.]]\n",
    "\n",
    "# Create a 3x3 identity matrix\n",
    "l = np.eye(3)\n",
    "print(l)\n",
    "# Output: [[1. 0. 0.]\n",
    "#          [0. 1. 0.]\n",
    "#          [0. 0. 1.]]\n",
    "\n",
    "m = np.diag([1, 2, 3])\n",
    "print(m)\n",
    "# Output: [[1 0 0]\n",
    "#          [0 2 0]\n",
    "#          [0 0 3]]\n",
    "\n",
    "n = np.full((2, 3), -1, dtype=float)\n",
    "print(n)\n",
    "# Output: [[-1. -1. -1.]\n",
    "#          [-1. -1. -1.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "\n",
    "Indexing and slicing operations are used to access specific elements or sub-arrays of a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The syntax for indexing and slicing a one-dimensional array is similar to\n",
    "# that of Python lists.\n",
    "\n",
    "# Create a one-dimensional array\n",
    "a = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Index the first element\n",
    "print(a[0])  # Output: 10\n",
    "\n",
    "# Index the last element\n",
    "print(a[-1])  # Output: 50\n",
    "\n",
    "# Slice the first three elements\n",
    "print(a[:3])  # Output: [10 20 30]\n",
    "\n",
    "# Slice the last two elements\n",
    "print(a[-2:])  # Output: [40 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and slicing for multi-dimensional numpy arrays are are more complex,\n",
    "# but also more powerful. You can use commas to separate the indices or slices\n",
    "# for each dimension of the array.\n",
    "\n",
    "# Create a two-dimensional array\n",
    "b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Index the element at row 1 and column 2\n",
    "print(b[1, 2])  # Output: 6\n",
    "\n",
    "# Index the element at row 0 and column -1\n",
    "print(b[0, -1])  # Output: 3\n",
    "\n",
    "# Slice the first two rows and all columns\n",
    "print(b[:2, :])  # Output: [[1 2 3]\n",
    "#          [4 5 6]]\n",
    "\n",
    "# Slice the last row and the first two columns\n",
    "print(b[-1, :2])  # Output: [7 8]\n",
    "\n",
    "# You can also use advanced indexing techniques, such as integer arrays or boolean arrays,\n",
    "# to select arbitrary elements or subarrays from an array.\n",
    "\n",
    "# Create a two-dimensional array\n",
    "c = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\n",
    "\n",
    "# Use an integer array to index the rows\n",
    "d = np.array([0, 2, 1])\n",
    "print(c[d, :])\n",
    "# Output: [[10 20 30]\n",
    "#          [70 80 90]\n",
    "#          [40 50 60]]\n",
    "\n",
    "# Use a boolean array to index the columns\n",
    "e = np.array([True, False, True])\n",
    "print(c[:, e])\n",
    "# Output: [[10 30]\n",
    "#          [40 60]\n",
    "#          [70 90]]\n",
    "\n",
    "# You can modify an array by assigning a new value to an index or subarray.\n",
    "print(b)\n",
    "# Output: [[1 2 3]\n",
    "#          [4 5 6]\n",
    "#          [7 8 9]]\n",
    "b[0, 1] *= 10\n",
    "print(b)\n",
    "# Output: [[ 1 20  3]\n",
    "#          [ 4  5  6]\n",
    "#          [ 7  8  9]]\n",
    "b[:, 2] = [-1, 0, 1]\n",
    "print(b)\n",
    "# Output: [[ 1 20 -1]\n",
    "#          [ 4  5  0]\n",
    "#          [ 7  8  1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Filtering is a technique to select a subset of an array that satisfies some criteria. For example, you may want to filter an array to get only the positive values, or only the even values, or only the values that match a certain condition. One way to filter an array is to use a boolean mask. A boolean mask is an array of the same shape as the original array, but with True or False values indicating which elements to keep or discard. You can create a boolean mask by applying a logical expression to the array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a two-dimensional array\n",
    "arr = np.array([[10, -20, 30], [-40, 50, -60], [70, -80, 90]])\n",
    "print(arr)\n",
    "# Output: [[ 10 -20  30]\n",
    "#          [-40  50 -60]\n",
    "#          [ 70 -80  90]]\n",
    "\n",
    "# # Create a boolean mask for positive values\n",
    "mask = arr > 0\n",
    "print(mask)\n",
    "# Output: [[ True False  True]\n",
    "#          [False  True False]\n",
    "#          [ True False  True]]\n",
    "\n",
    "# Apply the mask to the array to get the filtered array\n",
    "filtered_arr = arr[mask]\n",
    "print(filtered_arr)\n",
    "# Output: [10 30 50 70 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to filter an array is to use the `np.where()` function. This function takes a condition and returns the indices of the array where the condition is `True`. You can then use these indices to index the array and get the filtered array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Use np.where() to get the indices of even values\n",
    "indices = np.where(arr % 2 == 0)\n",
    "print(indices)\n",
    "# Output: (array([1, 3]),)\n",
    "\n",
    "# Use the indices to index the array and get the filtered array\n",
    "filtered = arr[indices]\n",
    "print(filtered)\n",
    "# Output: [2 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations and methods\n",
    "\n",
    "NumPy arrays support many basic operations that can be performed element-wise or with scalars. Element-wise operations are applied to each element of the array, while scalar operations are applied to the whole array as a single unit. Here are some examples of basic operations:\n",
    "\n",
    "- Arithmetic operations: NumPy arrays support the standard arithmetic operators `+`, `-`, `*`, `/`, and `**` for addition, subtraction, multiplication, division, and exponentiation, respectively These operators can be used between two arrays of the same shape, or between an array and a scalar. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two arrays of the same shape\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "# Add the two arrays element-wise\n",
    "print(a + b)\n",
    "# Output: [5 7 9]\n",
    "\n",
    "# Subtract the two arrays element-wise\n",
    "print(a - b)\n",
    "# Output: [-3 -3 -3]\n",
    "\n",
    "# Multiply the two arrays element-wise\n",
    "print(a * b)\n",
    "# Output: [ 4 10 18]\n",
    "\n",
    "# Divide the two arrays element-wise\n",
    "print(a / b)\n",
    "# Output: [0.25 0.4  0.5 ]\n",
    "\n",
    "# Raise the first array to the power of the second array element-wise\n",
    "print(a**b)\n",
    "# Output: [   1   32  729]\n",
    "\n",
    "# Add a scalar to an array\n",
    "print(a + 10)\n",
    "# Output: [11 12 13]\n",
    "\n",
    "# Multiply an array by a scalar\n",
    "print(a * 2)\n",
    "# Output: [2 4 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison operations: NumPy arrays support the standard comparison operators `<`, `>`, `<=`, `>=`, `==`, and `!=` for less than, greater than, less than or equal to, greater than or equal to, equal to, and not equal to, respectively. These operators can be used between two arrays of the same shape, or between an array and a scalar. The result is a boolean array of the same shape, indicating the outcome of each comparison. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two arrays of the same shape\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([3, 2, 1])\n",
    "\n",
    "# Compare the two arrays element-wise\n",
    "print(a < b)\n",
    "# Output: [ True False False]\n",
    "\n",
    "are_equal = a == b\n",
    "print(are_equal)\n",
    "# Output: [False  True False]\n",
    "\n",
    "# Compare an array with a scalar\n",
    "print(a > 2)\n",
    "# Output: [False False  True]\n",
    "\n",
    "print(a != 2)\n",
    "# Output: [ True False  True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays have many built-in methods and functions that can perform various operations on the data. Some of these methods and functions are:\n",
    "\n",
    "| Method | Description |\n",
    "| --- | --- |\n",
    "| `sum()` | Calculate the sum of all elements in the array, or along a specified axis. |\n",
    "| `max()` | Return the maximum value in the array, or along a specified axis. |\n",
    "| `min()` | Return the minimum value in the array, or along a specified axis. |\n",
    "| `mean()` | Calculate the mean of all elements in the array, or along a specified axis. |\n",
    "| `std()` | Calculate the standard deviation of all elements in the array, or along a specified axis. |\n",
    "| `argmax()` | Return the index of the maximum value in the array, or along a specified axis. |\n",
    "| `argmin()` | Return the index of the minimum value in the array, or along a specified axis. |\n",
    "| `dot()` | Calculate the dot product of two arrays. |\n",
    "| `reshape()` | Reshape an array. |\n",
    "| `flatten()` | Flatten an array. |\n",
    "| `sort()` | Sort an array. |\n",
    "| `unique()` | Find the unique elements in an array. |\n",
    "| `transpose()` or `T` | Transpose an array. |\n",
    "\n",
    "> *Notes*: \n",
    "> - You apply the above methods on NumPy arrays using the `.` operator, or you can use the equivalent functions with the `np.` prefix. For example, `np.sum(a)` is equivalent to `a.sum()`.\n",
    "> - We use the `axis=0` argument for row-wise operations and the `axis=1` argument for column-wise operations.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a two-dimensional array\n",
    "a = np.array([[1, 2, 3], [6, 5, 4]])\n",
    "print(a)\n",
    "# Output: [[1 2 3]\n",
    "#          [6 5 4]]\n",
    "\n",
    "# Sum all the elements\n",
    "print(a.sum())  # Output: 21\n",
    "\n",
    "# Sum the elements along the rows\n",
    "print(a.sum(axis=1))  # Output: [ 6 15]\n",
    "\n",
    "# Sum the elements along the columns\n",
    "print(a.sum(axis=0))  # Output: [7 7 7]\n",
    "\n",
    "print(a.min(), a.max(), sep=\", \")  # Output: 1, 6\n",
    "print(\"row minimums:\", a.min(axis=1))  # Output: [1 4]\n",
    "print(\"column maximums:\", a.max(axis=0))  # Output: [6 5 4]\n",
    "\n",
    "# Calculate the average of all elements\n",
    "print(a.mean())  # Output: 3.5\n",
    "\n",
    "# Calculate the standard deviation\n",
    "print(a.std())  # Output: 1.707825127659933\n",
    "\n",
    "# Calculate the mean along the rows\n",
    "print(a.mean(axis=1))  # Output: [2. 5.]\n",
    "\n",
    "# Calculate the standard deviation along the columns\n",
    "print(a.std(axis=0))  # Output: [2.5 1.5 0.5]\n",
    "\n",
    "# Find the index of the minimum and maximum elements\n",
    "print(a.argmin(axis=1), a.argmax(), sep=\", \")  # Output: [0 2], 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the array\n",
    "print(a.T)\n",
    "# Output: [[1 6]\n",
    "#          [2 5]\n",
    "#          [3 4]]\n",
    "print(a.transpose() == a.T)\n",
    "# Output: [[ True  True]\n",
    "#          [ True  True]\n",
    "#          [ True  True]]\n",
    "\n",
    "# Sort the array inplace\n",
    "a.sort()\n",
    "print(a)\n",
    "# Output: [[1 2 3]\n",
    "#          [4 5 6]]\n",
    "\n",
    "b = a.T\n",
    "b.sort(axis=0)  # Sort the columns\n",
    "print(b)\n",
    "# Output: [[1 4]\n",
    "#          [2 5]\n",
    "#          [3 6]]\n",
    "\n",
    "# Create two one-dimensional arrays\n",
    "c = np.array([1, 2, 3])\n",
    "d = np.array([4, 5, 6])\n",
    "\n",
    "# Calculate the dot product\n",
    "print(c.dot(d))  # Output: 32\n",
    "# Using the np.dot() function also works\n",
    "print(np.dot(c, d))  # Output: 32\n",
    "\n",
    "e = np.array([[1, 2], [3, 4]])\n",
    "f = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Calculate the dot product\n",
    "print(e.dot(f))\n",
    "# Output: [[19 22]\n",
    "#          [43 50]]\n",
    "\n",
    "# Reshape an array\n",
    "print(a)\n",
    "# Output: [[1 2 3]\n",
    "#          [4 5 6]]\n",
    "b = a.reshape(3, 2)\n",
    "print(b)\n",
    "# Output: [[1 2]\n",
    "#          [3 4]\n",
    "#          [5 6]]\n",
    "\n",
    "b = a.flatten()\n",
    "print(b)\n",
    "# Output: [1 2 3 4 5 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random arrays\n",
    "\n",
    "The `random` module in NumPy provides various functions for generating random arrays. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with 5 elements, randomly distributed between 0 and 1\n",
    "a = np.random.rand(5)\n",
    "print(a)\n",
    "\n",
    "# Create a two-dimensional array with integer elements randomly chosen from 1 to 100\n",
    "b = np.random.randint(1, 100, size=(3, 3))\n",
    "print(b)\n",
    "\n",
    "# You can specify the seed for the random number generator to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "c = np.random.randint(1, 100, size=(3, 3))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: A package for data analysis\n",
    "\n",
    "**Pandas** is a Python library that is used for data manipulation and analysis. Built on top of NumPy, Pandas provides a convenient and efficient way to work with various types of data, such as tabular data, time series, matrices, etc.\n",
    "\n",
    "To use Pandas, you need to install it in your Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import it using the alias `pd`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Pandas introduces two new data structures to Python: `Series` and `DataFrame`, which are both based on NumPy arrays.\n",
    "\n",
    "- `Series`: A Series is a one-dimensional array that can hold any type of data, such as numbers, strings, booleans, etc. A `Series` has an index, which labels each element in the array. Pandas `Series` can be created from a list, a dictionary, or a NumPy array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series from a list\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Print the Series\n",
    "print(s)\n",
    "\n",
    "# Access the element using indexing and slicing\n",
    "print(s[0])  # Output: 1\n",
    "values = s[2:-2]\n",
    "print(values)\n",
    "# Output: 2    3\n",
    "#         dtype: int64\n",
    "print(type(values))  # Prints <class 'pandas.core.series.Series'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `DataFrame`: A `DataFrame` is a two-dimensional array that can hold multiple columns of different types of data. A `DataFrame` has an index for the rows and columns, which can be customized or automatically generated. A `DataFrame` can be created from a dictionary, a list of lists, a NumPy array, or another `DataFrame`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [25, 30, 35], \"gender\": [\"F\", \"M\", \"M\"]}\n",
    "client_data = pd.DataFrame(my_data)\n",
    "\n",
    "# Show the DataFrame\n",
    "client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column in the DataFrame is a Series\n",
    "print(client_data[\"name\"])\n",
    "print(type(client_data[\"name\"]))  # Prints <class 'pandas.core.series.Series'>\n",
    "\n",
    "# Therefore you can access the elements using the index\n",
    "print(client_data[\"name\"][0])  # Prints Alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [[1, \"B\", True], [2, \"A\", False], [3, \"C\", True]]\n",
    "my_columns = [\"id\", \"grade\", \"passed\"]\n",
    "product_data = pd.DataFrame(my_data, columns=my_columns)\n",
    "\n",
    "print(product_data)\n",
    "# Output:\n",
    "#    id grade  passed\n",
    "# 0   1     B    True\n",
    "# 1   2     A   False\n",
    "# 2   3     C    True\n",
    "\n",
    "# Use the `shape` attribute to get the number of rows and columns\n",
    "print(product_data.shape)  # Output: (3, 3)\n",
    "# use the `len()` function to get the number of rows\n",
    "print(len(product_data))  # Output: 3\n",
    "print(len(product_data) == product_data.shape[0])  # Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common ways to use pandas is to read data from an external file and store it in a `DataFrame`. Pandas provides several functions to read different types of files, such as `read_csv()`, `read_excel()`, `read_sql()`, `read_json()`, etc. These functions return a `DataFrame` object that can be manipulated further. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file from a URL and store it in a DataFrame\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\")\n",
    "\n",
    "# Show the first five rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and manipulation of data\n",
    "\n",
    "The `index` of a pandas `DataFrame` is a special object that labels the rows of the `DataFrame`. The `index` can be a single column or a combination of columns, and it can have any type of values, such as numbers, strings, dates, etc. The `index` can be used to identify, select, and manipulate the rows of the `DataFrame` in various ways.\n",
    "\n",
    "- To access the `index` of a `DataFrame`, you can use the index attribute.\n",
    "- By default, the `index` is an integer sequence starting from 0. To change the `index` of a `DataFrame`, you can use the `set_index()` method. This method takes one or more columns as arguments and returns a new `DataFrame` with those columns as the `index`. You can also use the `inplace` parameter to modify the original DataFrame instead of creating a new one. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary\n",
    "client_data = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"id\": [\"1001\", \"1002\", \"1003\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"gender\": [\"F\", \"M\", \"M\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client_data.index)\n",
    "# Output: RangeIndex(start=0, stop=3, step=1)\n",
    "\n",
    "# Set the 'id' column as the index of the DataFrame\n",
    "new_client_data = client_data.set_index(\"id\")  # This creates a new DataFrame with a new index\n",
    "print(client_data)  # No changes to the original DataFrame!\n",
    "\n",
    "client_data.set_index(\"id\", inplace=True)  # This modifies the original DataFrame\n",
    "print(client_data)\n",
    "# Output:\n",
    "#          name  age gender\n",
    "# id\n",
    "# 1001    Alice   25      F\n",
    "# 1002      Bob   30      M\n",
    "# 1003  Charlie   35      M\n",
    "\n",
    "print(client_data.index)  # Prints Index(['1001', '1002', '1003'], dtype='int64', name='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing data using `loc` and `iloc`\n",
    "\n",
    "Pandas provides two methods for accessing data in a `DataFrame` using labels or positions: `loc` and `iloc`. These methods allow you to select rows, columns, or subsets of data using different types of arguments.\n",
    "\n",
    "- `loc`: The `loc[]` method is used for label-based indexing. It takes one or more labels as arguments and returns the rows or columns that match those labels. You can also use slicing notation or boolean arrays to select data using `loc[]`.\n",
    "- `iloc`: The `iloc[]` method is similar to `loc[]`, but it is used for position-based indexing. You can also use indexing/slicing notation or integer arrays to select data using `iloc[]`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = client_data.loc[\"1001\"]  # Select a single row based on the index\n",
    "print(row)\n",
    "# Output:\n",
    "# name    Alice\n",
    "# age        25\n",
    "# gender      F\n",
    "\n",
    "rows = client_data.loc[[\"1001\", \"1002\"]]  # Select multiple rows based on the index\n",
    "print(rows)\n",
    "# Output:\n",
    "#      name  age gender\n",
    "# id\n",
    "# 1001 Alice  25      F\n",
    "# 1002   Bob  30      M\n",
    "\n",
    "row = client_data.iloc[0]  # Select a single row based on the position\n",
    "print(row)\n",
    "# Output:\n",
    "# name    Alice\n",
    "# age       25\n",
    "# gender     F\n",
    "\n",
    "rows = client_data.iloc[[0, 1]]  # Select multiple rows based on the position\n",
    "print(rows)\n",
    "# Output:\n",
    "#      name  age gender\n",
    "# id\n",
    "# 1001 Alice  25      F\n",
    "# 1002   Bob  30      M\n",
    "\n",
    "rows = client_data.iloc[0:2]  # Select multiple rows based on the position\n",
    "print(rows)\n",
    "# Output:\n",
    "#      name  age gender\n",
    "# id\n",
    "# 1001 Alice  25      F\n",
    "# 1002   Bob  30      M\n",
    "\n",
    "# Select last two rows\n",
    "rows = client_data.iloc[-2:]\n",
    "print(rows)\n",
    "# Output:\n",
    "#          name  age gender\n",
    "# id\n",
    "# 1002      Bob   30      M\n",
    "# 1003  Charlie   35      M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns (without `loc` or `iloc`)\n",
    "column = client_data[\"name\"]  # Select a single column based on the column name\n",
    "print(column)\n",
    "# Output:\n",
    "# id\n",
    "# 1001    Alice\n",
    "# 1002      Bob\n",
    "# 1003  Charlie\n",
    "\n",
    "columns = client_data[[\"name\", \"age\"]]  # Select multiple columns based on the column name\n",
    "print(columns)\n",
    "# Output:\n",
    "#          name  age\n",
    "# id\n",
    "# 1001    Alice   25\n",
    "# 1002      Bob   30\n",
    "# 1003  Charlie   35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with `loc`\n",
    "column = client_data.loc[:, \"name\"]  # Select a single column based on the column name\n",
    "print(column)\n",
    "# Output:\n",
    "# id\n",
    "# 1001    Alice\n",
    "# 1002      Bob\n",
    "# 1003  Charlie\n",
    "\n",
    "columns = client_data.loc[:, [\"name\", \"age\"]]  # Select multiple columns based on the column name\n",
    "print(columns)\n",
    "# Output:\n",
    "#          name  age\n",
    "# id\n",
    "# 1001    Alice   25\n",
    "# 1002      Bob   30\n",
    "# 1003  Charlie   35\n",
    "\n",
    "table = client_data.loc[[\"1001\", \"1002\"], [\"name\", \"age\"]]  # Selecting rows and columns by labels\n",
    "print(table)\n",
    "# Output:\n",
    "#          name  age\n",
    "# id\n",
    "# 1001    Alice   25\n",
    "# 1002      Bob   30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with `iloc`\n",
    "columns = client_data.iloc[:, [0, 1]]  # Select multiple columns based on the position\n",
    "print(columns)\n",
    "# Output:\n",
    "#          name  age\n",
    "# id\n",
    "# 1001    Alice   25\n",
    "# 1002      Bob   30\n",
    "# 1003  Charlie   35\n",
    "\n",
    "table = client_data.iloc[-2:, 1:]  # Using positions\n",
    "print(table)\n",
    "# Output:\n",
    "#       age gender\n",
    "# id\n",
    "# 1002   30      M\n",
    "# 1003   35      M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and removing rows and columns\n",
    "\n",
    "Pandas allows you to add and remove rows and columns from a `DataFrame` using a label, `loc`, the `concat()` function, and the `drop()` method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"id\": [\"1001\", \"1002\", \"1003\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"gender\": [\"F\", \"M\", \"M\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new row\n",
    "new_row = [\"Linda\", \"1005\", 30, \"F\"]\n",
    "# Add the new row using a label as the index\n",
    "n = len(client_data)  # Evaluates to 3\n",
    "client_data.loc[n] = new_row\n",
    "# If the label already exists, the row will be replaced\n",
    "print(client_data)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 1      Bob  1002   30      M\n",
    "# 2  Charlie  1003   35      M\n",
    "# 3    Linda  1005   30      F\n",
    "\n",
    "# Remove a row using its label as the index\n",
    "client_data.drop(n, inplace=True)\n",
    "print(client_data)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 1      Bob  1002   30      M\n",
    "# 2  Charlie  1003   35      M\n",
    "\n",
    "# Remove the last row using its position\n",
    "client_data.drop(client_data.index[1], inplace=True)\n",
    "print(client_data)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 2  Charlie  1003   35      M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending rows from another DataFrame\n",
    "new_clients = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Adam\", \"Eve\"],\n",
    "        \"age\": [18, 18],\n",
    "        \"gender\": [\"M\", \"F\"],\n",
    "        \"id\": [\"2001\", \"2002\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "all_clients = pd.concat([client_data, new_clients])\n",
    "print(all_clients)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 2  Charlie  1003   35      M\n",
    "# 0     Adam  2001   18      M\n",
    "# 1      Eve  2002   18      F\n",
    "\n",
    "# Note that the index labels are not updated after appending.\n",
    "# You can use the ignore_index parameter to reset the index labels:\n",
    "all_clients = pd.concat([client_data, new_clients], ignore_index=True)\n",
    "print(all_clients)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 1  Charlie  1003   35      M\n",
    "# 2     Adam  2001   18      M\n",
    "# 3      Eve  2002   18      F\n",
    "\n",
    "# You can use the `reset_index()` method to assign default indices:\n",
    "all_clients.reset_index(drop=True, inplace=True)\n",
    "# If `drop=True`, the old index will be removed and a new one will be created\n",
    "# If `drop=False`, the old index will be kept as a new column and a new index will be created\n",
    "print(all_clients)\n",
    "\n",
    "# Adding a new column\n",
    "all_clients[\"city\"] = [\"Montreal\", \"Vancouver\", \"Toronto\", \"Toronto\"]\n",
    "print(all_clients)\n",
    "# Output:\n",
    "#       name  age gender       city\n",
    "# 0    Alice   25      F   Montreal\n",
    "# 1  Charlie   35      M  Vancouver\n",
    "# 2     Adam   18      M    Toronto\n",
    "# 3      Eve   18      F    Toronto\n",
    "\n",
    "# Removing columns\n",
    "all_clients.drop(\"city\", axis=1, inplace=True)\n",
    "print(all_clients)\n",
    "# Output:\n",
    "#       name    id  age gender\n",
    "# 0    Alice  1001   25      F\n",
    "# 1  Charlie  1003   35      M\n",
    "# 2     Adam  2001   18      M\n",
    "# 3      Eve  2002   18      F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on data manipulation\n",
    "\n",
    "Sometimes we want to add a new column whose values are derived from other columns. Some of the common methods are:\n",
    "\n",
    "- Using arithmetic operations: You can use arithmetic operators such as `+`, `-`, `*`, `/`, etc. to perform element-wise operations on existing columns and assign the result to a new column.\n",
    "- Using conditional logic: You can use conditional logic to create new columns based on the values of existing columns.\n",
    "- Using the `apply()` method: You can use the apply method to apply a custom function to existing columns and assign the result to a new column. The function can take one or more columns as arguments and return a single value for each row. \n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Nina\", \"Jim\", \"Katie\"],\n",
    "        \"age\": [16, 18, 19],\n",
    "        \"year_registered\": [2019, 2020, 2013],\n",
    "    }\n",
    ")\n",
    "\n",
    "current_year = 2024\n",
    "\n",
    "# Arithmetic operations:\n",
    "# Create a new column to store their age when they registered\n",
    "years_since_registration = current_year - student_data[\"year_registered\"]\n",
    "student_data[\"age_when_registered\"] = student_data[\"age\"] - years_since_registration\n",
    "print(student_data)\n",
    "# Output:\n",
    "#     name  age  year_registered  age_when_registered\n",
    "# 0   Nina   16             2019                   11\n",
    "# 1    Jim   18             2020                   14\n",
    "# 2  Katie   19             2013                    8\n",
    "\n",
    "# Using logical operators:\n",
    "# Create a new column to indicate if the client is an adult or not\n",
    "student_data[\"is_adult\"] = student_data[\"age\"] >= 18\n",
    "print(student_data)\n",
    "# Output:\n",
    "#     name  age  year_registered  age_when_registered  is_adult\n",
    "# 0   Nina   16             2019                   11     False\n",
    "# 1    Jim   18             2020                   14      True\n",
    "# 2  Katie   19             2013                    8      True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the `apply()` function:\n",
    "# Assume that we want to assign categories to our clients based on their registration year.\n",
    "# The clients are classified as \"old_client\" if they have been registered in the last 10 years.\n",
    "# Otherwise, they are classified as \"new_client\".\n",
    "\n",
    "\n",
    "# Create a function to assign categories\n",
    "def assign_category(year):\n",
    "    return \"old_client\" if current_year - year >= 10 else \"new_client\"\n",
    "\n",
    "\n",
    "# Create a new column to store the category by applying the function\n",
    "student_data[\"category\"] = student_data[\"year_registered\"].apply(assign_category)\n",
    "print(student_data)\n",
    "# Output:\n",
    "#     name  age  year_registered  age_when_registered  is_adult    category\n",
    "# 0   Nina   16             2019                   11     False  new_client\n",
    "# 1    Jim   18             2020                   14      True  new_client\n",
    "# 2  Katie   19             2013                    8      True  old_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Filtering and sorting\n",
    "\n",
    "Sometimes, you may want to filter a `DataFrame` based on certain conditions and select only the rows that satisfy those conditions. One common way to do this is using the `loc` attribute. This allows you to select rows based on a single condition or multiple conditions using boolean indexing. You can use operators such as `==`, `!=`, `<`, `>`, `<=`, `>=`, and `isin`. to compare column values with scalars or iterables. You can also use logical operators such as `&`, `|`, and `~` to combine multiple conditions with parentheses. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from a dictionary\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\"],\n",
    "        \"age\": [25, 30, 35, 40, 28, 32],\n",
    "        \"gender\": [\"F\", \"M\", \"M\", \"M\", \"F\", \"M\"],\n",
    "        \"salary\": [5000, 6000, 7000, 8000, 5500, 6500],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Filter rows where gender is F using loc\n",
    "df_f = df.loc[df[\"gender\"] == \"F\"]\n",
    "\n",
    "print(df_f)\n",
    "# Output:\n",
    "#     name  age gender  salary\n",
    "# 0  Alice   25      F    5000\n",
    "# 4    Eve   28      F    5500\n",
    "\n",
    "# Filter rows where age is between 30 and 39\n",
    "df_age = df.loc[(df[\"age\"] >= 30) & (df[\"age\"] < 40)]\n",
    "\n",
    "print(df_age)\n",
    "# Output:\n",
    "#       name  age gender  salary\n",
    "# 1      Bob   30      M    6000\n",
    "# 2  Charlie   35      M    7000\n",
    "# 5    Frank   32      M    6500\n",
    "\n",
    "# Filter rows where name is in a list using loc\n",
    "mask = df[\"name\"].isin([\"Alice\", \"Bob\"])\n",
    "df_name = df.loc[mask]\n",
    "\n",
    "print(df_name)\n",
    "# Output:\n",
    "#     name  age gender  salary\n",
    "# 0  Alice   25      F    5000\n",
    "# 1    Bob   30      M    6000\n",
    "\n",
    "# Filter rows where name is not in a list\n",
    "# Use the `~` operator to invert the mask\n",
    "df_name = df.loc[~mask]\n",
    "print(df_name)\n",
    "# Output:\n",
    "#       name  age gender  salary\n",
    "# 2  Charlie   35      M    7000\n",
    "# 3    David   40      M    8000\n",
    "# 4      Eve   28      F    5500\n",
    "# 5    Frank   32      M    6500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you may want to sort a Pandas `DataFrame` based on a column or a set of columns in ascending or descending order. In this case, you can use the `sort_values()` method to sort the `DataFrame` by the values in the specified column. You can pass the name or list of names of the columns to sort. You can also specify the `ascending` argument to control whether the `DataFrame` is sorted in ascending or descending order. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Eve\", \"David\", \"Charlie\", \"Frank\"],\n",
    "        \"age\": [25, 30, 35, 40, 30, 32],\n",
    "        \"gender\": [\"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n",
    "        \"salary\": [5500, 6000, 7000, 8000, 5000, 6500],\n",
    "    }\n",
    ")\n",
    "\n",
    "df.sort_values(by=\"age\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by salary in descending order\n",
    "df.sort_values(by=\"salary\", ascending=False, inplace=True)\n",
    "print(df)\n",
    "# Output:\n",
    "#       name  age gender  salary\n",
    "# 3    David   40      M    8000\n",
    "# 2      Eve   35      F    7000\n",
    "# 5    Frank   32      M    6500\n",
    "# 1      Bob   30      M    6000\n",
    "# 0    Alice   25      F    5500\n",
    "# 4  Charlie   30      M    5000\n",
    "\n",
    "# sort by gender then by salary\n",
    "df.sort_values(by=[\"gender\", \"salary\"], inplace=True)\n",
    "print(df)\n",
    "# Output:\n",
    "#       name  age gender  salary\n",
    "# 0    Alice   25      F    5500\n",
    "# 2      Eve   35      F    7000\n",
    "# 4  Charlie   30      M    5000\n",
    "# 1      Bob   30      M    6000\n",
    "# 5    Frank   32      M    6500\n",
    "# 3    David   40      M    8000\n",
    "\n",
    "# sort by gender in ascending order then by salary in descending order\n",
    "df.sort_values(by=[\"gender\", \"salary\"], ascending=[True, False], inplace=True)\n",
    "print(df)\n",
    "# Output:\n",
    "#       name  age gender  salary\n",
    "# 2      Eve   35      F    7000\n",
    "# 0    Alice   25      F    5500\n",
    "# 3    David   40      M    8000\n",
    "# 5    Frank   32      M    6500\n",
    "# 1      Bob   30      M    6000\n",
    "# 4  Charlie   30      M    5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data aggregation\n",
    "\n",
    "Data aggregation is a process of transforming and summarizing data into a more compact and meaningful form. Data aggregation can help you to perform various types of data analysis, such as finding patterns, trends, outliers, correlations, etc. Data aggregation can also help you to reduce the complexity and size of your data, making it easier to understand and visualize.\n",
    "\n",
    "One of the most common ways to perform data aggregation on a Pandas `DataFrame` is to use the `groupby()` method. This method allows you to split a `DataFrame` into groups based on one or more columns, and then apply a function to each group. The function can be an aggregation function, such as `sum()`, `mean()`, `count()`, etc., or a custom function defined by the user. The result is a new `DataFrame` with the aggregated values for each group.\n",
    "\n",
    "Another way to perform data aggregation using Pandas dataframes is to use the `pivot_table()` method. This method allows you to create a multidimensional table from a `DataFrame`, where the rows and columns are defined by one or more columns, and the values are defined by an aggregation function. The `pivot_table()` method can help you to reshape and reorganize your data, and to create cross-tabulations and contingency tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Eve\", \"David\", \"Charlie\", \"Frank\"],\n",
    "        \"age\": [25, 30, 35, 40, 30, 32],\n",
    "        \"gender\": [\"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n",
    "        \"salary\": [5500, 6000, 7000, 8000, 5000, 6500],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Assume that we are interested in the mean salary for each gender\n",
    "grouped = df.groupby(\"gender\")\n",
    "salaries = grouped[\"salary\"]\n",
    "# print the size of each group\n",
    "print(grouped.size())\n",
    "# Output:\n",
    "# gender\n",
    "# F    2\n",
    "# M    4\n",
    "\n",
    "# print the mean salary\n",
    "print(salaries.mean())\n",
    "# Output:\n",
    "# gender\n",
    "# F    6250.0\n",
    "# M    6375.0\n",
    "\n",
    "# Find out, for each gender, how many people are at least 30 years old\n",
    "grouped = df.loc[df[\"age\"] >= 30].groupby(\"gender\")\n",
    "print(grouped.size())\n",
    "# Output:\n",
    "# gender\n",
    "# F    1\n",
    "# M    4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pivot table\n",
    "# find the minimum salary for each gender\n",
    "pivoted = df.pivot_table(index=\"gender\", values=\"salary\", aggfunc=\"min\")\n",
    "print(pivoted)\n",
    "# Output:\n",
    "#         salary\n",
    "# gender\n",
    "# F         5500\n",
    "# M         5000\n",
    "\n",
    "\n",
    "# add a new column to the dataframe\n",
    "def get_category(age):\n",
    "    return \"old\" if age > 30 else \"young\"\n",
    "\n",
    "\n",
    "df[\"age_category\"] = df[\"age\"].apply(get_category)\n",
    "\n",
    "# Find the mean salary for each age category indexed by gender\n",
    "# Using multi-index\n",
    "pivoted = df.pivot_table(index=[\"gender\", \"age_category\"], values=\"salary\", aggfunc=\"mean\")\n",
    "print(pivoted)\n",
    "# Output:\n",
    "#                      salary\n",
    "# gender age_category\n",
    "# F      old           7000.0\n",
    "#        young         5500.0\n",
    "# M      old           7250.0\n",
    "#        young         5500.0\n",
    "\n",
    "# Using the `columns` argument\n",
    "pivoted = df.pivot_table(index=\"gender\", columns=\"age_category\", values=\"salary\", aggfunc=\"mean\")\n",
    "print(pivoted)\n",
    "# Output:\n",
    "# age_category     old   young\n",
    "# gender\n",
    "# F             7000.0  5500.0\n",
    "# M             7250.0  5500.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib and Seaborn: Visualizing data\n",
    "\n",
    "Data visualization is an important skill for data analysis, as it can help you to explore, understand, and communicate your data. By leveraging the power of `pandas` and utilizing data visualization libraries such as Matplotlib and Seaborn, you can create various types of plots that can reveal patterns, trends, outliers, relationships, and more in your data.\n",
    "\n",
    "First, let's install Matplotlib and Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Note*: We can also install multiple packages at once by separating them with spaces. The above command installs both `matplotlib` and `seaborn` at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Matplotlib\n",
    "\n",
    "**Matplotlib** is a low-level library that provides a comprehensive set of tools for creating and customizing plots. Pandas' built-in integration with matplotlib offers some useful methods for plotting dataframes and series.\n",
    "\n",
    "To plot some basic plots using matplotlib and pandas, you need to follow these steps:\n",
    "\n",
    "1. Import the libraries: `import matplotlib.pyplot as plt`\n",
    "2. Load or create your data as a pandas dataframe or series\n",
    "3. Choose the type of plot that suits your data and your analysis goal\n",
    "4. Use the `plot()` method of the dataframe or series, and pass the `kind` argument to specify the type of plot, such as `kind='line'`, `kind='box'`, `kind='hist'`, or `kind='scatter'`\n",
    "5. Customize your plot by adding labels, titles, legends, etc. using `matplotlib` functions such as `plt.xlabel()`, `plt.title()`, `plt.legend()`, etc.\n",
    "6. Show or save your plot using `plt.show()` or `plt.savefig()`\n",
    "\n",
    "Here are some examples of basic plots using `matplotlib` and `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Alternatively, you can write:\n",
    "# from mathplotlib import pyplot as plt\n",
    "\n",
    "dataset_url = \"https://raw.githubusercontent.com/m-mehdi/pandas_tutorials/main/weekly_stocks.csv\"\n",
    "# read the data from the URL, parse the dates, and set the index to the date\n",
    "df = pd.read_csv(dataset_url, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "# only include the second half of 2021 data\n",
    "df = df.loc[\"2021-07-01\":\"2021-12-31\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a line plot and see how Microsoft performed over time:\n",
    "df.plot(kind=\"line\", y=\"MSFT\", figsize=(8, 5))\n",
    "# The `figsize` argument takes two arguments, and allowing us to change the size of the output figure.\n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Microsoft Stock Prices\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel(\"Price ($)\")\n",
    "# Set the x-axis label\n",
    "plt.xlabel(\"Date\")\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can plot columns in the same plot\n",
    "df.plot(kind=\"hist\", y=[\"MSFT\", \"FB\"], bins=20, alpha=0.5)\n",
    "# Using the bins argument to set the number of bins in the histogram.\n",
    "# Using the alpha argument to set the transparency of bar colors.\n",
    "# The default `figsize` is used if not specified.\n",
    "\n",
    "plt.title(\"Stock Prices\")\n",
    "# plt.ylabel(\"Price ($)\")\n",
    "# plt.xlabel(\"Date\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a box plot of the closing prices\n",
    "df.plot(kind=\"box\", y=df.columns)  # Plot for all columns\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "\n",
    "**Seaborn** is another library for data visualization in Python, which is built on top of `matplotlib` and `pandas`. Seaborn offers a higher-level interface and more attractive default styles for creating various types of plots, such as histograms, scatter plots, box plots, line plots, etc. Seaborn also integrates well with Pandas dataframes and supports statistical analysis and inference.\n",
    "\n",
    "You can import `seaborn` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # sns for 'seaborn name space'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will use `sns` to plot some basic plots using `pandas` and `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"tips\" dataset from the Seaborn library\n",
    "df = sns.load_dataset(\"tips\")\n",
    "print(type(df))  # Prints <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "# Description of the dataset:\n",
    "# - total_bill: Total bill (including tip).\n",
    "# - tip: Tip amount.\n",
    "# - sex: Gender of the payer (Male or Female).\n",
    "# - smoker: Whether the party was a smoker (Yes or No).\n",
    "# - day: Day of the week (Thur, Fri, Sat, Sun).\n",
    "# - time: Time of day (Lunch or Dinner).\n",
    "# - size: Size of the party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot with no error bars\n",
    "sns.lineplot(df, x=\"day\", y=\"total_bill\", hue=\"smoker\")\n",
    "# The `hue` argument is used to group the data by the `smoker` column.\n",
    "plt.show()\n",
    "# You can pass the `errorbar=None` argument to the `lineplot()` function\n",
    "# to remove the error areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a histogram with multiple categories, showing\n",
    "sns.histplot(df, x=\"tip\", hue=\"sex\", alpha=0.3)\n",
    "plt.xlabel(\"Tip ($)\")  # Setting the x-axis label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df, x=\"size\", y=\"total_bill\", hue=\"sex\")\n",
    "plt.ylabel(\"Total bill ($)\")  # Setting the y-axis label\n",
    "# Remove the legend title and set\n",
    "# the legend position to \"upper center\"\n",
    "plt.legend(title=None, loc=\"upper center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the maximum tip amount for each day of the week using a horizontal bar chart\n",
    "ax1, ax2 = \"day\", \"tip\"\n",
    "grouped = df.groupby(ax1, observed=True)[ax2].max().reset_index()\n",
    "print(grouped)\n",
    "# Output:\n",
    "#     day    tip\n",
    "# 0  Thur   6.70\n",
    "# 1   Fri   4.73\n",
    "# 2   Sat  10.00\n",
    "# 3   Sun   6.50\n",
    "\n",
    "sns.barplot(grouped, x=ax2, y=ax1, orient=\"h\")  # `orient=\"h\"` for horizontal bar chart\n",
    "plt.title(\"Maximum Tip Amount by Day of the Week\")\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, you can use matplotlib on the grouped data:\n",
    "grouped.plot(kind=\"barh\", x=ax1, y=ax2)\n",
    "plt.title(\"Maximum Tip Amount by Day of the Week\")\n",
    "plt.show()\n",
    "\n",
    "# Or, use seaborn's `estimator` argument for the original data:\n",
    "# No need to use `groupby`\n",
    "sns.barplot(df, x=ax2, y=ax1, estimator=np.max, errorbar=None, orient=\"h\")\n",
    "plt.title(\"Maximum Tip Amount by Day of the Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(df, x=\"total_bill\", y=\"tip\")\n",
    "plt.title(\"Regression Plot of Total Bill vs Tip\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
